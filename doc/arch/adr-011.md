# Title

Inter-Task communication

# Status

Accepted

# Context

The kernel needs a mechanism to send and receive data between tasks. 

As explained in [Os wiki](https://wiki.osdev.org/IPC_Data_Copying_methods), there are many ways to exchange data between processes which do not share the same address space but they can roughly be classified in two families : asynchronous and synchronous messaging mechanisms. There are pros and cons for the two approaches, no one is better but one is more suited to fit for certain use cases.

Anckor is inspired by microkernel designs : it heavily relies on its IPC mechanism performance as many parts of the system aim to be implemented in user space. Kernels designed with the same constraints such as **L4** have stated that synchronous message passing shows a better performance (see [5.2.3 in this paper](https://dl.acm.org/doi/pdf/10.1145/173668.168633)). Also, the aim of the kernel is to design highly predictable, easy-to-understand systems and **[Hubris](https://hubris.oxide.computer/reference/#ipc)** explains why synchronous IPC is more suited for this goal.

For these two reasons, we will now focus on **synchronous message passing** implementations.

## Client / Server protocol

Several information can be found in **[QNX reference documentation](https://www.qnx.com/developers/docs/6.5.0SP1.update/com.qnx.doc.neutrino_sys_arch/ipc.html)** about how the client / server protocol is implemented. This can be summerized in the two following diagrams:

```C                                                           
                         CLIENT STATE MACHINE                        
                                                  ┌─────────┐        
           ┌───────┐                              │  SEND   │        
           │ READY ├──────────────────────────────►         │        
           └▲────┬─┘    Client does MsgSend()     │ blocked │        
            │    │                                └────┬────┘        
            │    │                                     │             
Server does │    │ Client does                         │ Server does 
 MsgReply() │    │ MsgSend()                           │ MsgReceive()
            │    │                                     │                  
            │    │                                     │             
          ┌─┴────▼──┐                                  │             
          │  REPLY  │                                  │             
          │         ◄──────────────────────────────────┘             
          │ blocked │                                                
          └─────────┘                                                
                                                                     
                                                                     
                         SERVER STATE MACHINE                        
                                                                     
   Server does MsgReply()                                            
            ┌──────┐                                                 
            │      │                                                 
            │    ┌─▼───────┐ Server does MsgRcv() ┌─────────┐        
            └────┤         ├──────────────────────► RECEIVE │        
                 │  READY  │                      │         │        
            ┌────►         ◄──────────────────────┤ blocked │        
            │    └─┬───────┘ Client does MsgSend()└─────────┘        
            │      │                                                 
            └──────┘                                                 
   Server does MsgRcv()                                              
   it returns immediatly if client is in SEND_blocked state               
```

**L4** IPC also uses **direct process switch** (described in [5.3.5](https://www.cs.hs-rm.de/~kaiser/2020_aos/05b-ukx6.pdf)) to switch the flow control from the sender to the receiver without calling the scheduler.

## Register-based communication channel

Synchronous communication enables to reduce the number of copies needed to move data from the sender to the receiver. Only one copy is required to send data from one address space to the other (as we don't need to save data temporary in kernel space).

Some kernels such as **L4** implements a **shared memory** strategy to optimize this copy (details are described in [5.2.3 in this paper](https://dl.acm.org/doi/pdf/10.1145/173668.168633)). In this scenario, page tables of the receive task is updated to **temporary map the data memory area in its address space**. Once data are mapped, the receiver task can copy it (which leads to the only **one copy** needed) or directly consume it. In the latter case, we need more **complex synchronization as the sender task is blocked until the receiver task has consumed it**.

**Shared memory** can be seen as a communication channel we use to exchange the data. For short messages (such as just a few bytes), a further optimization can be implemented : use **cpu registers as a communication channel**([see 5.3.6 in this paper](https://dl.acm.org/doi/pdf/10.1145/173668.168633)). One implementation of a such mechanism can be seen in **SeL4** and its **fastpath** ipc: 

```C
                 ┌────────────┐                                  
                 │ trap_entry │                                  
                 └──────┬─────┘                                  
                        │                                        
                        │ if the trap is due to a syscall        
                        │                                        
                ┌───────▼───────┐                                
                │ fastpath_call │                                
                └───────┬───────┘                                
                        │                                        
data length ┌───────────┴────────────────┐  data length          
 > 4 bytes  │                            │  <= 4 bytes           
            │                            │                       
     ┌──────▼───┐             ┌──────────▼───────────┐           
     │ slowpath │             │ copy tcb src regs in │           
     └──────────┘             │     tcb dst regs     │           
                              └──────────┬───────────┘           
                                         │                       
                         ┌───────────────▼─────────────────┐     
                         │ set dst thread state to RUNNING │     
                         └───────────────┬─────────────────┘     
                                         │                       
                             ┌───────────▼──────────────┐        
                             │ set address space to dst │        
                             │  thread's address space  │        
                             └───────────┬──────────────┘        
                                         │                       
                        ┌────────────────▼─────────────────────┐ 
                        │ copy 4-bytes word in a dedicated reg │ 
                        └────────────────┬─────────────────────┘ 
                                         │                       
                       ┌─────────────────▼──────────────────────┐
                       │ restore all dst registers from its tcb │
                       └────────────────────────────────────────┘
```

A similar approach is also described in [D. Cheriton](https://dl.acm.org/doi/epdf/10.1145/850766.850768) and [page 18 of this course](https://www.cs.hs-rm.de/~kaiser/2020_aos/05b-ukx6.pdf). The advantage of this approach is **performance** as the read / write operations from cpu registers are **very fast**.

## API

The **A653** standard defines a convenient API to open a communication port and exchange data through it: 

```C
SamplingPort CREATE_SAMPLING_PORT(const char* portName, SamplingRate rate, BufferSize bufferSize, ErrorCode* error);

ErrorCode WRITE_SAMPLING_MESSAGE(SamplingPort port, const SampleData* data, size_t dataSize);

ErrorCode READ_SAMPLING_MESSAGE(SamplingPort port, SampleData* dataBuffer, size_t* dataSize);

PortID GET_SAMPLING_PORT_ID(SamplingPort port);
```

**lk** offers a similar API:

```C
status_t port_create(const char *name, port_mode_t mode, port_t *port);

status_t port_open(const char *name, void *ctx, port_t *port);

status_t port_write(port_t port, const port_packet_t *pk, size_t count);

status_t port_read(port_t port, lk_time_t timeout, port_result_t *result);
```

Such API offers two advantages:
- due to **port indirection**, communication is executed with access controls. This allows to block a thread sending a message to a thread for which it has no access.
- ports are identified through their **names** so they can be created and opened in two different programs with different address spaces.

# Decision

Following the previous analysis, the following *Key Decisions* are made :
- **Synchronous based communication** : enables to efficiently send / receive data and synchronize tasks between them
- **Direct process switch** : avoids priority inversion and improve performance
- **Register-based communication channel** : only short messages are supported
- **Channel indirection** : IPC do not use thread IDs as endpoints, this enables to control access to the channel

## Client / Server protocol

Exchanges between tasks are handled through state diagrams similar to those described in **QNX documentation**: 

```C
                         CLIENT STATE MACHINE             
                                                          
            ┌─────────┐                        ┌─────────┐
            │         │                        │         │
            │ RUNNING │                        │ BLOCKED │
            │         ├────────────────────────►         │
            └─┬─────▲─┘     channel_snd()      └────┬────┘
              │     │        & !rcv_rdy             │     
              │     │                               │     
              │     │                               │     
channel_snd() │     │ channel_rcv()                 │     
  & rcv_rdy   │     │                               │     
              │     │                               │     
            ┌─▼─────┴─┐                             │     
            │         │       channel_rcv()         │     
            │  READY  ◄─────────────────────────────┘     
            │         │                                   
            └─────────┘                                   
                                                          
                                                          
                         SERVER STATE MACHINE             
                                                          
            ┌─────────┐      channel_snd()     ┌─────────┐
            │         ◄────────────────────────┤         │
            │ RUNNING │                        │ BLOCKED │
            │         ├────────────────────────►         │
            └─────────┘      channel_rcv()     └─────────┘
```

A **rcv_rdy** flag is used to know if a task is ready to receive the message. If its not the case, the send task goes to **BLOCKED** state. 

When a task is already waiting to receive data (**rcv_rdy** is **true**), a **direct process switch** occurs without calling the scheduler.

Using **rcv_rdy** flag makes it possible to avoid adding dedicated states in the scheduler such as **SEND_BLOCKED** or **RECEIVE_BLOCKED**. The aim is to isolate scheduler mechanism from channels implementation. We want the coupling between these two functions to be as minimal as possible.

The **rcv** and **snd** opoerations are summarized in the sequence diagrams below:

```C

```

# Consequences

Only handles register based messaging, limited amount of data. For longer messages, we should implement a [direct transfer method](https://dl.acm.org/doi/pdf/10.1145/173668.168633).

Also, the current implementation uses processor registers as a communication channel between tasks. That's very fast but it cannot work if tasks do not run on the same core.

Not SMP-ready right now, need to check the channel access / release protocol when receive and send task do not run on the same processor.

Lastly, we do not check if the tasks have rights to access to the channel before sending or receiving messages. We could check it and immediatly return an error if a task attempts to access to a channel for which it has not requested access.