# Title

Tasks creation and context switching

# Status

Accepted

# Context

We need a way to manage tasks creation, running and context switching. 

# Decision

All tasks information are saved in a **task_t** structure which is defined as followed: 

```c
typedef struct task_t {
  task_id_t    task_id;
  uint8_t      prio;
  task_state_t state;
  stack_t     *stack;
  thread_t     thread;
} task_t;
```

Each field is defined here after:
- **task_id**: assigned by the kernel for each new task. The **Idle task** has task_id 0.
- **prio**: task priority
- **state**: each task can be in a different state but they are all initialized in **ready** state. Only one task can be in the **running** state at a time.
- **stack**: base address of the task stack. Each task is running in its own stack and this field is needed for cleaning the memory when a task is destroyed.
- **thread**: used to store CPU registers used by the context switching procedure. This is architecture specific information.

In this text, examples talking about **thread_t** data are related to **riscv architecture** but the same reasoning can be applied for other architectures.

As seen in [linux](https://elixir.bootlin.com/linux/v6.3.8/source/include/asm-generic/vmlinux.lds.h#L411), **task_t** data are stored in the **task stack**: 

```c
                     Task stack
 stack_start ┌────────────────────────┐
             │                        │
             │                        │
             │          ...           │
             │                        │
             │                        │
  thread->sp ├────────────────────────┤
             │   task_runtime() address    │
             ├────────────────────────┤
             │       task data        │
             │ ...                    │
             │ task_id                │
             │ prio                   │
             │ state                  │
             │ ...                    │
             │      thread data       │
             │ ra                     │
             │ sp                     │
             │ s[0]                   │
             │ ...                    │
             │ s[11]                  │
             │ a[0] = task_entry      │
             │ ...                    │
             │ a[7]                   │
             │ t[0]                   │
             │ ...                    │
             │ t[6]                   │
   stack_end └────────────────────────┘
```

When a task is created, all task data are initialized. Thread data are set with an **architecture specific** procedure called **task_init_stack** (which is inspired by [riot](https://github.com/RIOT-OS/RIOT/blob/master/core/include/thread.h#L414)).

Task data are initialized as if the task has been interrupted before. This enables to start a task with the generic **context_switch** mechanism: from the **_switch_to** procedure point of view, starting or resuming a task is the same thing. 

To do this, task data are carefully initialized: 
- a **task_runtime** procedure is placed on the top of the stack. This is used to call the task **main procedure** and is very close to **z_thread_entry** in [zephyr](https://github.com/zephyrproject-rtos/zephyr/blob/main/lib/os/thread_entry.c#L30).
- **thread.sp** is updated to save the new top of stack.
- **ra** doesn't need to be initalized, as it will be overriden by **sched_run** (as explained later).

When a context switch occurs, **sched_switch** is called:

```c
__no_inline static void sched_switch(task_t *prev_task, task_t *new_task) {
  _switch_to(&prev_task->thread, &new_task->thread);
}
```

The **function preamble saves the return address on the top of the current task stack** then jumps to **_switch_to**. This **return address** contains the next instruction of the current task to run. Now, **_switch_to** is used to save the current task context and load the next one:

```asm
_switch_to:
    # save previous thread context
    sd sp, TASK_THREAD_SP(a0)
    sd s0, TASK_THREAD_S0(a0)
    ...
    sd s11, TASK_THREAD_S11(a0)

    # load next thread context
    ld sp, TASK_THREAD_SP(a1)
    ld s0, TASK_THREAD_S0(a1)
    ...
    ld s11, TASK_THREAD_S11(a1)
    
    ret
```

As **sched_run** is only called in **cooperative** mode, so we just have to store and load **callee saved** registers. **ra** doesn't appear here because we want to return at the end of **sched_run**. When **_switch_to** returns, the context of the new task is loaded so **sched_run** will load **task_runtime** from the top of the stack before exiting. **task_runtime** now runs with the task **main function** passed as its argument (through the register **a[0]**).

The exact same code path executes when a context switch occurs with already running tasks. The only difference is the **return address** saved on the top of the stack will be the address stored by the **sched_run preamble**, not the address of **task_runtime**.

This process is illustrated just below when only the **idle_task** is running.

```C
       Task_A

   ┌──────────────┐
   │ task_yield() │             stack(A)
   └──────┬───────┘                 ▲
          │                         │
   ┌──────▼─────────┐
   │ sched_switch() │ sd ra, OFFSET(sp)
   └──────┬─────────┘
          │
    ┌─────▼──────┐
    │ _switch_to │ ISA updates ra = sched_switch()
    └─────┬──────┘ when jumping into _switch_to
          │
   ┌──────▼─────────┐
   │ sched_switch() │ ld ra, OFFSET(SP)
   └──────┬─────────┘
          │                         │
   ┌──────▼───────┐                 ▼
   │ task_yield() │             stack(A)
   └──────────────┘
```

As no other task is scheduled, **_switch_to** save and load the **idle_task** context. If a second task is scheduled, a context switch occurs as described here after.

```C

      Task_A                                                Task_B

  ┌──────────────┐
  │ task_yield() │             stack(A)
  └──────┬───────┘                 ▲
         │                         │
  ┌──────▼─────────┐
  │ sched_switch() │ sd ra, OFFSET(sp)
  └──────┬─────────┘
         │
         │                  ┌────────────┐
         └──────────────────► _switch_to ├──────────────────┐
                            └────────────┘                  │
                     ISA updates ra = sched_switch()        │
                     when jumping into _switch_to    ┌──────▼─────────┐
                                                     │ sched_switch() │ ld ra, OFFSET(sp)
                                                     └──────┬─────────┘
                                                            │                         │
                                                     ┌──────▼─────────┐               ▼
                                                     │ task_runtime() │            stack(B)
                                                     └──────┬─────────┘
                                                            │
                                                      ┌─────▼────────┐
                                                      │ task_entry() │
                                                      └──────────────┘
```

If ever the task main procedure returns (which should not occur), **task_destroy** is called in **task_runtime** to clean memory and remove the task from scheduler queues.

# Consequences

Context switchs only appear in a **cooperative** way which enables to have a generic and lightweight **_switch_to** function. 

Each task stack is carefully designed and initialized as if the task had already been interrupted once. Starting a task is equivalent to resuming it with **_switch_to**.

This mechanism is not compatible with a **preemptive** scheduling scheme where tasks can be switched at any time by hardware interruptions. This case shall be handled by a dedicated mechanism. 